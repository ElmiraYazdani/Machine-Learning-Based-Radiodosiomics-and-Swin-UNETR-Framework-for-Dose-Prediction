{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp6l5j9h-nes"
      },
      "source": [
        "# Feature Selection Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUQNU6gr2ch8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poRPXW6QW4qE"
      },
      "outputs": [],
      "source": [
        "!pip install xgboost --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evpWTJymwCSM"
      },
      "outputs": [],
      "source": [
        "!pip install mpl-chord-diagram\n",
        "!pip install eli5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5MDUAzOwCSO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
        "from sklearn.linear_model import Lasso, LassoCV, LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge, HuberRegressor, SGDRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
        "from sklearn.model_selection import KFold, cross_val_score, train_test_split, learning_curve, LeaveOneOut\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "from scipy.stats import spearmanr, pearsonr, false_discovery_control, linregress\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJ0d-muPwCSe"
      },
      "outputs": [],
      "source": [
        "def get_simple_feature_name(feature_names):\n",
        "    simple_names = []\n",
        "    for feature_name in feature_names:\n",
        "        simple_name=feature_name\n",
        "        pattern = r'\\((.*)'\n",
        "        match = re.search(pattern, feature_name)\n",
        "        if match:\n",
        "            simple_name = match.group(1)\n",
        "            if simple_name in simple_names:\n",
        "                last_underscore_index = feature_name.rfind('_')\n",
        "                simple_name = feature_name[last_underscore_index:] if last_underscore_index != -1 else feature_name\n",
        "        simple_names.append(simple_name)\n",
        "    return simple_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ja_Sx9vVwCSf"
      },
      "outputs": [],
      "source": [
        "def one_hot_encoding(df, feature_name):\n",
        "    if feature_name in df.columns:\n",
        "        encoder = OneHotEncoder(sparse_output=False)\n",
        "        encoded_data = encoder.fit_transform(df[[feature_name]])\n",
        "        one_hot_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out([feature_name]))\n",
        "        df = pd.concat([df, one_hot_df], axis=1)\n",
        "        df = df.drop(feature_name, axis=1)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LK9MFIuVwCSi"
      },
      "outputs": [],
      "source": [
        "def hist_plot(df):\n",
        "    df_renamed = df.copy()\n",
        "    df_renamed.columns = get_simple_feature_name(df.columns)\n",
        "    df_renamed.hist(figsize=(16, 20), bins=50, xlabelsize=8, ylabelsize=8)\n",
        "    plt.grid(True, linewidth=0.5)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YILLBWWmwCSk"
      },
      "outputs": [],
      "source": [
        "def pair_plot(X, y):\n",
        "    X_renamed = X.copy()\n",
        "    X_renamed.columns = get_simple_feature_name(X.columns)\n",
        "    y_df = y.to_frame().rename(columns={0: 'Dose'})\n",
        "    df = pd.concat([X_renamed, y_df], axis=1)\n",
        "\n",
        "    num_features = len(X.columns)\n",
        "    num_cols = 3\n",
        "    num_rows = (num_features + num_cols - 1) // num_cols\n",
        "    fig, axes = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(15, 5 * num_rows))\n",
        "\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        if i < num_features:\n",
        "            feature = df.columns[i]\n",
        "            ax.scatter(df[feature], df['DOSE'])\n",
        "            slope, intercept, r_value, p_value, std_err = linregress(df[feature], df['DOSE'])\n",
        "            ax.plot(df[feature], slope * df[feature] + intercept, color='green')\n",
        "            ax.set_xlabel(feature)\n",
        "            ax.set_ylabel('Dose')\n",
        "            ax.text(0.05, 0.95, f'r = {r_value:.3f}\\np = {p_value:.3f}', transform=ax.transAxes, va='top')\n",
        "        else:\n",
        "            ax.axis('off')\n",
        "    plt.grid(True, linewidth=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPQY9i7KwCSk"
      },
      "outputs": [],
      "source": [
        "def plot_chord_diagram(X):\n",
        "    fig, ax = plt.subplots(figsize=(12, 12))\n",
        "    chord_diagram(X.corr(), names=get_simple_feature_name(X.columns), ax=ax, rotation=0, fontsize=11)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZPBRqJVwCSl"
      },
      "outputs": [],
      "source": [
        "def plot_learning_curve(X, y, model, cv):\n",
        "    fig, ax = plt.subplots(figsize=(10, 6), sharex=True)\n",
        "\n",
        "    common_params = {\n",
        "        \"X\":X,\n",
        "        \"y\": y,\n",
        "        \"train_sizes\": np.linspace(0.1, 1.0, 5, 20),\n",
        "        \"cv\": cv,\n",
        "        \"n_jobs\": 4,\n",
        "        \"return_times\": True,\n",
        "        \"scoring\":'neg_mean_squared_error'\n",
        "    }\n",
        "    train_sizes, train_scores, test_scores, fit_times, score_times = learning_curve(\n",
        "        model, **common_params\n",
        "    )\n",
        "\n",
        "    ax.plot(fit_times.mean(axis=1), -train_scores.mean(axis=1),\"o-\", label=\"Training Score\")\n",
        "    ax.plot(fit_times.mean(axis=1), -test_scores.mean(axis=1), \"o-\", label=\"Validation Score\")\n",
        "    ax.fill_between(\n",
        "        fit_times.mean(axis=1),\n",
        "        train_scores.mean(axis=1) - train_scores.std(axis=1),\n",
        "        train_scores.mean(axis=1) + train_scores.std(axis=1),\n",
        "        alpha=0.3,\n",
        "    )\n",
        "    ax.fill_between(\n",
        "        fit_times.mean(axis=1),\n",
        "        test_scores.mean(axis=1) - test_scores.std(axis=1),\n",
        "        test_scores.mean(axis=1) + test_scores.std(axis=1),\n",
        "        alpha=0.3,\n",
        "    )\n",
        "    ax.set_ylabel(\"MSE score\")\n",
        "    ax.set_xlabel(\"Fit time (s)\")\n",
        "    ax.set_title(\n",
        "        f\"Performance of the {model.__class__.__name__} classifier\"\n",
        "    )\n",
        "    plt.grid(True, linewidth=0.5)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SJV7-2swCSm"
      },
      "outputs": [],
      "source": [
        "def pca_analysis(X_selected):\n",
        "\n",
        "    pca = PCA()\n",
        "    X_pca = pca.fit_transform(StandardScaler().fit_transform(X_selected))\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_)\n",
        "    plt.xlabel('Number of principal components')\n",
        "    plt.ylabel('Explained variance ratio')\n",
        "    plt.title('Scree plot')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.scatter(X_pca[:, 0], X_pca[:, 1], s=20, alpha=0.5)\n",
        "    plt.xlabel('PC1')\n",
        "    plt.ylabel('PC2')\n",
        "    plt.title('Scatter plot of the first two principal components')\n",
        "    plt.show()\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZG-NKUtwCSn"
      },
      "outputs": [],
      "source": [
        "def plot_prediction_graph(y, y_pred, r2):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(y, y_pred, color='#1f77b4', alpha=0.6)\n",
        "    plt.plot(np.linspace(min(y), max(y), 100), np.linspace(min(y), max(y), 100), color='red', linewidth=2)\n",
        "    plt.xlabel('Measured Dose(GY/GBq)', fontsize=14)\n",
        "    plt.ylabel('Predicted Dose(GY/GBq)', fontsize=14)\n",
        "    plt.title(f\"Predicted vs. Actual (R-squared: {r2:.3f})\", fontsize=16, color='#333333')\n",
        "    plt.text(0.05, 0.95, f\"R²: {r2:.3f}\", transform=plt.gca().transAxes, va='top', fontsize=11, color='#333333')\n",
        "    plt.grid(True, linewidth=0.5)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9TcKsxJ-Xoe"
      },
      "outputs": [],
      "source": [
        "def plot_prediction_graph2(y, y_pred, r2):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.regplot(x=y, y=y_pred,\n",
        "            scatter_kws=dict(color='#00008B', alpha=0.6),\n",
        "            line_kws=dict(color='#FE420F'))\n",
        "    plt.plot(np.linspace(min(y), max(y), 100), np.linspace(min(y), max(y), 100), color='black', linestyle='--', label='Identity Line')\n",
        "    plt.xlabel('Measured Dose (Gy/ GBq)', fontsize=12)\n",
        "    plt.ylabel('Predicted Dose (Gy/ GBq)', fontsize=12)\n",
        "    plt.title(f'R²: {r2:.2f}', fontsize=12)\n",
        "    plt.legend(loc='upper left', fontsize=10)\n",
        "    plt.grid(True, linewidth=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNrhK5aTwCSn"
      },
      "outputs": [],
      "source": [
        "def calculate_scores(y, y_pred, r2_required=True):\n",
        "    r2 = -1\n",
        "    if (r2_required):\n",
        "        r2 = r2_score(y, y_pred)\n",
        "    mae = mean_absolute_error(y, y_pred)\n",
        "    mse = mean_squared_error(y, y_pred)\n",
        "    mape = mean_absolute_percentage_error(y, y_pred)\n",
        "    return r2, mae, mse, mape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfBSaYcmwCSp"
      },
      "outputs": [],
      "source": [
        "def print_scores(mode, r2_scores, mae_scores, mse_scores, rmse_scores, mape_scores, corr_score):\n",
        "    print(\"\\nMean\", mode, \"Scores:\")\n",
        "    print(\"Mean R2 Score:\", np.mean(r2_scores))\n",
        "    print(\"Mean MAE:\", np.mean(mae_scores))\n",
        "    print(\"Mean MSE:\", np.mean(mse_scores))\n",
        "    print(\"Mean RMSE:\", np.mean(rmse_scores))\n",
        "    print(\"Mean MAPE:\", np.mean(mape_scores))\n",
        "    print(\"Spearman Correlation:\", corr_score)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRM2iC6ZwCSq"
      },
      "outputs": [],
      "source": [
        "def p_value_correction(X, y, alpha=0.05):\n",
        "    p_values = []\n",
        "    for col in X.columns:\n",
        "        _, p = spearmanr(X[col], y)\n",
        "        p_values.append(p)\n",
        "\n",
        "    corrected_p_values = false_discovery_control(p_values, method='bh')\n",
        "\n",
        "    print(\"Corrected p-values:\")\n",
        "    for feature, p_value in zip(X.columns, corrected_p_values):\n",
        "        print(f\"{feature}: {p_value:.10f}\")\n",
        "\n",
        "    selected_features = [feature for feature, p_val in zip(X.columns, corrected_p_values) if p_val < alpha]\n",
        "    removed_features = [feature for feature, p_val in zip(X.columns, corrected_p_values) if p_val >= alpha]\n",
        "\n",
        "    print()\n",
        "    print(\"Removed features:\")\n",
        "    print(removed_features)\n",
        "    return X[selected_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mUmd05MwCSr"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(X_selected, y, model, cv, print_results=True):\n",
        "\n",
        "    r2_train_scores = []\n",
        "    mae_train_scores = []\n",
        "    mse_train_scores = []\n",
        "    rmse_train_scores = []\n",
        "    mape_train_scores = []\n",
        "\n",
        "    r2_test_scores = []\n",
        "    mae_test_scores = []\n",
        "    mse_test_scores = []\n",
        "    rmse_test_scores = []\n",
        "    mape_test_scores = []\n",
        "\n",
        "    y_tests=[]\n",
        "    y_test_preds=[]\n",
        "\n",
        "    y_trains=[]\n",
        "    y_train_preds=[]\n",
        "\n",
        "    for train_idx, test_idx in cv.split(X_selected, y):\n",
        "\n",
        "        X_train, X_test = X_selected[train_idx], X_selected[test_idx]\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        y_train_pred = model.predict(X_train)\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "        y_tests += list(y_test)\n",
        "        y_test_preds += list(y_test_pred)\n",
        "\n",
        "        y_trains += list(y_train)\n",
        "        y_train_preds += list(y_train_pred)\n",
        "\n",
        "        r2_train, mae_train, mse_train, mape_train = calculate_scores(y_train, y_train_pred)\n",
        "\n",
        "        if isinstance(cv, LeaveOneOut):\n",
        "            r2_test, mae_test, mse_test, mape_test = calculate_scores(y_test, y_test_pred, False)\n",
        "        else:\n",
        "            r2_test, mae_test, mse_test, mape_test = calculate_scores(y_test, y_test_pred)\n",
        "\n",
        "        r2_train_scores.append(r2_train)\n",
        "        mae_train_scores.append(mae_train)\n",
        "        mse_train_scores.append(mse_train)\n",
        "        rmse_train_scores.append(np.sqrt(mse_train))\n",
        "        mape_train_scores.append(mape_train)\n",
        "\n",
        "        r2_test_scores.append(r2_test)\n",
        "        mae_test_scores.append(mae_test)\n",
        "        mse_test_scores.append(mse_test)\n",
        "        rmse_test_scores.append(np.sqrt(mse_test))\n",
        "        mape_test_scores.append(mape_test)\n",
        "\n",
        "    corr_train, _ = spearmanr(y_trains, y_train_preds)\n",
        "    corr_test, _ = spearmanr(y_tests, y_test_preds)\n",
        "\n",
        "    if isinstance(cv, LeaveOneOut):\n",
        "        r2_test_scores = r2_score(y_tests, y_test_preds)\n",
        "\n",
        "    if (print_results):\n",
        "        print_scores('Train', r2_train_scores, mae_train_scores, mse_train_scores, rmse_train_scores, mape_train_scores, corr_train)\n",
        "\n",
        "        print_scores('Test', r2_test_scores, mae_test_scores, mse_test_scores, rmse_test_scores, mape_test_scores, corr_test)\n",
        "\n",
        "    return np.mean(r2_test_scores), np.mean(r2_train_scores), np.mean(mse_test_scores), y_trains, y_train_preds, y_tests, y_test_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDarfBbIwCSs"
      },
      "outputs": [],
      "source": [
        "\n",
        "def evaluate_based_on_feature_number2(X_sorted, y, model, cv):\n",
        "    num_features_list = []\n",
        "    r2_scores = []\n",
        "    mse_scores = []\n",
        "\n",
        "    for num_features in range(X_sorted.shape[1], 1, -1):\n",
        "        X_selected = X_sorted[:, :num_features]\n",
        "\n",
        "        r2, mse, y_tests, y_pred_tests = evaluate_model(X_selected, y, model, cv, print_results=False)\n",
        "\n",
        "        num_features_list.append(num_features)\n",
        "        r2_scores.append(r2)\n",
        "        mse_scores.append(mse)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(num_features_list, r2_scores, marker='o', label='R^2 Score')\n",
        "    plt.xlabel('Number of Selected Features')\n",
        "    plt.ylabel('R^2 Score')\n",
        "    plt.title('R^2 Score vs. Number of Selected Features')\n",
        "    plt.xticks(num_features_list)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(num_features_list, mse_scores, marker='x', label='Mean Squared Error')\n",
        "    plt.xlabel('Number of Selected Features')\n",
        "    plt.ylabel('Mean Squared Error')\n",
        "    plt.title('Mean Squared Error vs. Number of Selected Features')\n",
        "    plt.xticks(num_features_list)\n",
        "    plt.legend()\n",
        "    plt.grid(True, linewidth=0.5)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KafuCdhcwCSs"
      },
      "outputs": [],
      "source": [
        "\n",
        "def evaluate_based_on_feature_number2(X_sorted, y, model, cv):\n",
        "    num_features_list = []\n",
        "    r2_scores = []\n",
        "    mse_scores = []\n",
        "\n",
        "    for num_features in range(X_sorted.shape[1], 1, -1):\n",
        "        X_selected = X_sorted[:, :num_features]\n",
        "\n",
        "        r2, mse, y_tests, y_pred_tests = evaluate_model(X_selected, y, model, cv, print_results=False)\n",
        "\n",
        "        num_features_list.append(num_features)\n",
        "        r2_scores.append(r2)\n",
        "        mse_scores.append(mse)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(num_features_list, r2_scores, marker='o', label='R^2 Score')\n",
        "    plt.xlabel('Number of Selected Features')\n",
        "    plt.ylabel('R^2 Score')\n",
        "    plt.title('R^2 Score vs. Number of Selected Features')\n",
        "    plt.xticks(num_features_list)\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(num_features_list, mse_scores, marker='x', label='Mean Squared Error')\n",
        "    plt.xlabel('Number of Selected Features')\n",
        "    plt.ylabel('Mean Squared Error')\n",
        "    plt.title('Mean Squared Error vs. Number of Selected Features')\n",
        "    plt.xticks(num_features_list)\n",
        "    plt.legend()\n",
        "    plt.grid(True, linewidth=0.5)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zCBCjzZa4UK"
      },
      "outputs": [],
      "source": [
        "def fit(self, X, y):\n",
        "    self.model_ = self.build_fn()\n",
        "    y = np.array(y).reshape(-1, 1)\n",
        "    self.model_.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=self.verbose)\n",
        "    return self\n",
        "\n",
        "def predict(self, X):\n",
        "    predictions = self.model_.predict(X)\n",
        "    return predictions.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mT_oJB_h513o"
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_excel(\"/content/drive/MyDrive/dosiomics/LDVK.xlsx\")\n",
        "df2 = pd.read_excel(\"/content/drive/MyDrive/dosiomics/LCT.xlsx\")\n",
        "\n",
        "df1.columns = [col + '_DRM' for col in df1.columns]\n",
        "\n",
        "df2.drop(['DOSE'], axis=1, inplace=True)\n",
        "df2.columns = [col + '_CT' for col in df2.columns]\n",
        "#df = pd.concat([df1, df2], axis=1)\n",
        "\n",
        "# clinical.drop(columns=['PATIENT', 'DOSE'], axis=1, inplace=True)\n",
        "\n",
        "# pet_ct_clinical = pd.concat([pet_ct, clinical_imputed], axis=1)\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "df0 = pd.read_excel(\"/content/drive/MyDrive/dosiomics/LB.xlsx\")\n",
        "\n",
        "numeric_cols = df0.select_dtypes(include='number').columns.tolist()\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', num_pipeline, numeric_cols),\n",
        "    ])\n",
        "\n",
        "df3 = pd.DataFrame(preprocessor.fit_transform(df0), columns=numeric_cols)\n",
        "df3.drop(['DOSE'], axis=1, inplace=True)\n",
        "df3.columns = [col + '_CB' for col in df3.columns]\n",
        "\n",
        "df = pd.concat([df1,df2,df3], axis=1)\n",
        "df4= pd.concat([df1,df2], axis=1)\n",
        "#df1: DVK only\n",
        "#df2: CT only\n",
        "#df3: CB only\n",
        "#df4: DVK+CT\n",
        "#df: all\n",
        "\n",
        "\n",
        "#E1: DVK + CT ....>feature selection: df4\n",
        "#E2: DVK+CT+CB....>feature selection: df\n",
        "#E3: result E1 + whole CBs: selected features df4 + d0 (whole CBs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omr7gbIqwCSt"
      },
      "outputs": [],
      "source": [
        "y=df['DOSE_DRM']\n",
        "X=df.drop('DOSE_DRM', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16hcTZAhwCSu"
      },
      "outputs": [],
      "source": [
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "X_selected = X\n",
        "X_selected_encoded = one_hot_encoding(X_selected, 'LOC')\n",
        "X_selected_scaled = StandardScaler().fit_transform(X_selected_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFGRjYx3zR2M"
      },
      "source": [
        "**RFE feature selection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kc4_fwRDlSvE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "estimator = GradientBoostingRegressor()\n",
        "num_features = 10\n",
        "\n",
        "rfe = RFE(estimator, n_features_to_select=num_features)\n",
        "rfe.fit(X_selected_scaled, y)\n",
        "\n",
        "selected_features = X.columns[rfe.support_]\n",
        "\n",
        "for f, feature in enumerate(selected_features):\n",
        "    print(\"%d. Feature %s\" % (f + 1, feature))\n",
        "\n",
        "estimator.fit(X_selected_scaled, y)\n",
        "\n",
        "feature_importances = estimator.feature_importances_\n",
        "\n",
        "selected_feature_importance = [(selected_features[i], feature_importances[X.columns.get_loc(selected_features[i])])\n",
        "                               for i in range(num_features)]\n",
        "\n",
        "selected_feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "rfe_final_features, importances = zip(*selected_feature_importance)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(rfe_final_features, importances, color='#993366')\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.title('Feature Importance of Selected Features after RFE')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5A_z5FW7f-O"
      },
      "source": [
        "Creating X_selected_sorted_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgvVVV5d6mr8"
      },
      "outputs": [],
      "source": [
        "encoded_cols = X_selected_encoded.columns\n",
        "name_to_idx = {col: i for i, col in enumerate(encoded_cols)}\n",
        "\n",
        "idx_final = np.array([name_to_idx[f] for f in rfe_final_features], dtype=int)\n",
        "\n",
        "rfe_ranks_kept = rfe.ranking_[rfe.support_]\n",
        "order = np.argsort(rfe_ranks_kept)\n",
        "idx_final_sorted = idx_final[order]\n",
        "\n",
        "X_selected_sorted = X_selected_scaled[:, idx_final_sorted]\n",
        "\n",
        "print(\"Column indices of RFE final features:\", idx_final_sorted)\n",
        "print(\"Ordered feature names:\", encoded_cols[idx_final_sorted].tolist())\n",
        "\n",
        "X_selected_sorted_df = pd.DataFrame(\n",
        "    X_selected_sorted,\n",
        "    columns=encoded_cols[idx_final_sorted],\n",
        "    index=X_selected_encoded.index\n",
        ")\n",
        "\n",
        "X_selected_sorted_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9CuZOLTv7ac"
      },
      "source": [
        "**Mutual-information feature selection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JClQVld_vk04"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import mutual_info_regression, SelectKBest\n",
        "\n",
        "num_features = 10\n",
        "\n",
        "mi_selector = SelectKBest(score_func=mutual_info_regression,\n",
        "                          k=num_features)\n",
        "mi_selector.fit(X_selected_scaled, y)\n",
        "\n",
        "mi_support = mi_selector.get_support()\n",
        "\n",
        "mi_selected_features = X.columns[mi_support]\n",
        "mi_scores = mi_selector.scores_[mi_support]\n",
        "\n",
        "mi_feature_importance = sorted(zip(mi_selected_features, mi_scores),\n",
        "                               key=lambda x: x[1], reverse=True)\n",
        "\n",
        "mi_final_features, importances = zip(*mi_feature_importance)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(mi_final_features, importances, color='#336699')\n",
        "plt.xlabel('Mutual Information Score')\n",
        "plt.title('Top {} Features Chosen by Mutual Information'.format(num_features))\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oSi-3Hy8hQL"
      },
      "source": [
        "Creating X_selected_sorted_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXq0zrQh7oAd"
      },
      "outputs": [],
      "source": [
        "encoded_cols = X_selected_encoded.columns\n",
        "name_to_idx = {col: i for i, col in enumerate(encoded_cols)}\n",
        "\n",
        "idx_final = np.array([name_to_idx[f] for f in mi_final_features], dtype=int)\n",
        "\n",
        "rfe_ranks_kept = rfe.ranking_[rfe.support_]\n",
        "order = np.argsort(rfe_ranks_kept)\n",
        "idx_final_sorted = idx_final[order]\n",
        "\n",
        "X_selected_sorted = X_selected_scaled[:, idx_final_sorted]\n",
        "\n",
        "print(\"Column indices of mi final features:\", idx_final_sorted)\n",
        "print(\"Ordered feature names:\", encoded_cols[idx_final_sorted].tolist())\n",
        "\n",
        "X_selected_sorted_df = pd.DataFrame(\n",
        "    X_selected_sorted,\n",
        "    columns=encoded_cols[idx_final_sorted],\n",
        "    index=X_selected_encoded.index\n",
        ")\n",
        "\n",
        "X_selected_sorted_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RbTGO7qKe_f"
      },
      "source": [
        "**boruta feature selection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukTZ0QOLKepS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "def boruta_feature_selection_kbest(\n",
        "        X: pd.DataFrame,\n",
        "        y,\n",
        "        *,\n",
        "        n_iters: int = 30,\n",
        "        top_k: int = 10,\n",
        "        rf_kwargs: dict | None = None,\n",
        "        random_state: int | None = None\n",
        "):\n",
        "    rng = np.random.default_rng(random_state)\n",
        "    rf_opts = dict(n_estimators=100, n_jobs=-1, random_state=random_state)\n",
        "    if rf_kwargs:\n",
        "        rf_opts.update(rf_kwargs)\n",
        "\n",
        "    hits = np.zeros(X.shape[1], dtype=int)\n",
        "    cols = X.columns.to_numpy()\n",
        "\n",
        "    for _ in tqdm(range(n_iters), desc=\"Boruta iterations\", unit=\"iter\"):\n",
        "        shadow = pd.DataFrame(\n",
        "            rng.permutation(X.values),\n",
        "            columns=[f\"shadow_{c}\" for c in cols],\n",
        "            index=X.index\n",
        "        )\n",
        "        X_expanded = pd.concat([X, shadow], axis=1)\n",
        "\n",
        "        rf = RandomForestRegressor(**rf_opts)\n",
        "        rf.fit(X_expanded, y)\n",
        "\n",
        "        importances = rf.feature_importances_\n",
        "        max_shadow_imp = importances[len(cols):].max()\n",
        "        hits += (importances[:len(cols)] > max_shadow_imp)\n",
        "\n",
        "    idx_sorted = np.argsort(-hits)[:top_k]\n",
        "    chosen_features = cols[idx_sorted]\n",
        "    chosen_hits = hits[idx_sorted]\n",
        "\n",
        "    order = np.argsort(chosen_hits)\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.barh(chosen_features[order], chosen_hits[order], color=\"#228B22\")\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.xlabel(\"Hit count\")\n",
        "    plt.title(f\"Boruta top {top_k} features\")\n",
        "    plt.show()\n",
        "\n",
        "    return list(chosen_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHGcC07N8kKQ"
      },
      "source": [
        "Creating X_selected_sorted_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNls7c50SgBs"
      },
      "outputs": [],
      "source": [
        "X_df = pd.DataFrame(X_selected_scaled, columns=X_selected_encoded.columns)\n",
        "top10 = boruta_feature_selection_kbest(X_df, y, n_iters=30, top_k=10, random_state=42)\n",
        "print(top10)\n",
        "X_selected_sorted_df = X_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7K_Gvt6rWrU"
      },
      "source": [
        "**ElasticNet Feature Selection**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0t3ZoX0grkSg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import ElasticNetCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Parameters\n",
        "k_final = 16\n",
        "random_state = 42\n",
        "\n",
        "# X_selected_scaled: your scaled data (numpy array)\n",
        "# X_selected_encoded: your encoded DataFrame with column names\n",
        "X0 = pd.DataFrame(X_selected_scaled, columns=X_selected_encoded.columns)\n",
        "y0 = y\n",
        "\n",
        "# ElasticNetCV pipeline\n",
        "enet = make_pipeline(\n",
        "    StandardScaler(with_mean=False),\n",
        "    ElasticNetCV(l1_ratio=0.9, cv=5, random_state=random_state, max_iter=5000)\n",
        ")\n",
        "enet.fit(X0, y0)\n",
        "\n",
        "# Extract and rank coefficients\n",
        "abs_coefs = np.abs(enet[-1].coef_)\n",
        "idx_sorted = np.argsort(-abs_coefs)[:min(k_final, len(abs_coefs))]\n",
        "feat_elasticnet = X0.columns[idx_sorted]\n",
        "X_enet_selected = X0.iloc[:, idx_sorted]\n",
        "\n",
        "# Output\n",
        "print(f\"\\nTop {k_final} features selected by ElasticNet:\")\n",
        "for i, f in enumerate(feat_elasticnet, 1):\n",
        "    print(f\"{i}. {f}\")\n",
        "\n",
        "# Optional: Return DataFrame of selected features\n",
        "X_enet_selected_df = pd.DataFrame(X_enet_selected, columns=feat_elasticnet, index=X_selected_encoded.index)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIaeAPC79Aj7"
      },
      "source": [
        "Creating X_selected_sorted_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r28gSxtWu0v-"
      },
      "outputs": [],
      "source": [
        "# Already computed earlier:\n",
        "# - feat_elasticnet: top k_final feature names sorted by |ElasticNet coefficient|\n",
        "# - X0: DataFrame with feature names\n",
        "# - X_selected_scaled: scaled feature matrix\n",
        "# - X_selected_encoded: original encoded DataFrame (with same column order)\n",
        "\n",
        "# Map feature names to column indices\n",
        "encoded_cols = X_selected_encoded.columns\n",
        "name_to_idx = {col: i for i, col in enumerate(encoded_cols)}\n",
        "\n",
        "# Get indices of selected features (already in order of importance)\n",
        "idx_final_sorted = np.array([name_to_idx[f] for f in feat_elasticnet], dtype=int)\n",
        "\n",
        "# Select sorted feature columns from the scaled matrix\n",
        "X_selected_sorted = X_selected_scaled[:, idx_final_sorted]\n",
        "\n",
        "# Print indices and names of selected features\n",
        "print(\"Column indices of ElasticNet-selected features:\", idx_final_sorted)\n",
        "print(\"Ordered feature names:\", encoded_cols[idx_final_sorted].tolist())\n",
        "\n",
        "# Create DataFrame of the selected features\n",
        "X_selected_sorted_df = pd.DataFrame(\n",
        "    X_selected_sorted,\n",
        "    columns=encoded_cols[idx_final_sorted],   # ordered feature names\n",
        "    index=X_selected_encoded.index            # preserve the original row index\n",
        ")\n",
        "\n",
        "X_selected_sorted_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LASSO Feature Selection**"
      ],
      "metadata": {
        "id": "wUtHydo8GxIG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Op7lm6LtGX83"
      },
      "outputs": [],
      "source": [
        "\n",
        "# LASSO feature selection\n",
        "lasso = Lasso(alpha=0.01, max_iter=100000)\n",
        "lasso.fit(X_selected_scaled, y)\n",
        "\n",
        "# Get the feature importance from the LASSO model\n",
        "lasso_coef = lasso.coef_\n",
        "lasso_importance = np.abs(lasso_coef)\n",
        "lasso_importance_sorted = np.argsort(lasso_importance)[::-1]\n",
        "\n",
        "# Select the top n features\n",
        "selected_features = X.columns[lasso_importance_sorted[:num_features]]\n",
        "\n",
        "for f, feature in enumerate(selected_features):\n",
        "    print(\"%d. Feature %s\" % (f + 1, feature))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def lasso_feature_selection_kbest(\n",
        "    X: pd.DataFrame,\n",
        "    y,\n",
        "    *,\n",
        "    alpha: float = 0.1,\n",
        "    top_k: int = 10,\n",
        "    max_iter: int = 100000,\n",
        "    random_state: int = 42\n",
        "):\n",
        "    # Fit LASSO model\n",
        "    lasso = Lasso(alpha=alpha, max_iter=max_iter, random_state=random_state)\n",
        "    lasso.fit(X, y)\n",
        "\n",
        "    # Coefficients and importance\n",
        "    lasso_coef = lasso.coef_\n",
        "    lasso_importance = np.abs(lasso_coef)\n",
        "\n",
        "    # Sort feature indices by importance (descending)\n",
        "    sorted_idx = np.argsort(lasso_importance)[::-1]\n",
        "\n",
        "    # Select top_k non-zero features\n",
        "    top_features_idx = [i for i in sorted_idx if lasso_coef[i] != 0][:top_k]\n",
        "    selected_features = X.columns[top_features_idx]\n",
        "\n",
        "    # Create sorted DataFrame\n",
        "    X_selected_sorted_df = X[selected_features]\n",
        "\n",
        "    # Optional: print top features\n",
        "    for f, feature in enumerate(selected_features):\n",
        "        print(f\"{f + 1}. Feature: {feature}, Coef: {lasso_coef[X.columns.get_loc(feature)]:.4f}\")\n",
        "\n",
        "    return X_selected_sorted_df\n",
        "\n",
        "# Example usage:\n",
        "X_df = pd.DataFrame(X_selected_scaled, columns=X_selected_encoded.columns)\n",
        "X_selected_sorted_df = lasso_feature_selection_kbest(X_df, y, top_k=10)\n"
      ],
      "metadata": {
        "id": "TnnLO6VJIE73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyDg3Fruyoax"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUBOQCdA7CRB"
      },
      "outputs": [],
      "source": [
        "X_selected_corrected = p_value_correction(X_selected_sorted_df, y)\n",
        "X_selected_corrected.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfT_mD9O7CJY"
      },
      "outputs": [],
      "source": [
        "X_selected_encoded = one_hot_encoding(X_selected_sorted_df, 'LOC')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evgO6J70UIEZ"
      },
      "outputs": [],
      "source": [
        "X_selected_scaled = StandardScaler().fit_transform(X_selected_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ib3eifMUTIM"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "class KerasRegressor(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, build_fn, epochs=100, batch_size=32, verbose=0):\n",
        "        self.build_fn = build_fn\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.verbose = verbose\n",
        "        self.model_ = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vpDucF0UTF7"
      },
      "outputs": [],
      "source": [
        "loo = LeaveOneOut()\n",
        "\n",
        "for train_idx, test_idx in loo.split(X_selected_scaled, y):\n",
        "    print(f\"Train set size: {len(train_idx)}\")\n",
        "    print(f\"Test set size: {len(test_idx)}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKQ7MJX-UTDU"
      },
      "outputs": [],
      "source": [
        "best_r2 = -np.inf\n",
        "best_model = None\n",
        "x=106\n",
        "\n",
        "models = [\n",
        "    #LinearRegression(),\n",
        "    #Ridge(),\n",
        "    #Lasso(),\n",
        "    #ElasticNet(),\n",
        "    #RandomForestRegressor(random_state=x),\n",
        "    GradientBoostingRegressor(random_state=x),\n",
        "    XGBRegressor(random_state=x),\n",
        "    ExtraTreesRegressor(random_state=x),\n",
        "    #SVR(),\n",
        "    #DecisionTreeRegressor(random_state=x),\n",
        "    #BayesianRidge(),\n",
        "    #KNeighborsRegressor(),\n",
        "    AdaBoostRegressor(random_state=x),\n",
        "    #HuberRegressor(),\n",
        "    #SGDRegressor(random_state=x),\n",
        "    #KerasRegressor(build_modell, epochs=100, batch_size=32, verbose=0)\n",
        "]\n",
        "\n",
        "for model in models:\n",
        "    print(f\"Evaluating {type(model).__name__}:\")\n",
        "\n",
        "    r2_test, r2_train, mse_test, y_trains, y_train_preds, y_tests, y_test_preds = evaluate_model(X_selected_scaled, y, model, loo)\n",
        "\n",
        "    if (r2_test > best_r2):\n",
        "        best_r2 = r2_test\n",
        "        best_model = model\n",
        "print(\"Best model: \",  type(best_model).__name__)\n",
        "print(\"Best R2: \",  best_r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzmgAZghwCTM"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = XGBRegressor(random_state=106)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q10C6xsHKKLh"
      },
      "outputs": [],
      "source": [
        "r2_test, r2_train, mse_test, y_trains, y_train_preds, y_tests, y_pred_tests = evaluate_model(X_selected_scaled, y, model, loo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TDuduUnKZlT"
      },
      "outputs": [],
      "source": [
        "def plot_prediction_graph2(y_test, y_pred_test, r2_test):\n",
        "\n",
        "    _, p_value = pearsonr(y_test, y_pred_test)\n",
        "\n",
        "    q_value = false_discovery_control(p_value, method='bh')\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "#4B878BFF, #D01C1FFF, #FF7057, #00B9AB\n",
        "\n",
        "    sns.regplot(x=y_test, y=y_pred_test,\n",
        "                scatter_kws=dict(color='#b300b3', alpha=0.6, s=33),\n",
        "                line_kws=dict(color='#1E90FF', linewidth=2))\n",
        "    plt.plot(np.linspace(min(y), max(y), 100), np.linspace(min(y), max(y), 100), color='black', linestyle='--', linewidth=1.3, label='Identity Line')\n",
        "    plt.xlabel('Measured Dose (Gy/ GBq)', fontsize=18)\n",
        "    plt.ylabel('Predicted Dose (Gy/ GBq)', fontsize=18)\n",
        "    plt.text(0.48, 1.1, f'R² Test: {r2_test:.2f}', horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes, fontsize=18, fontweight='bold')\n",
        "    plt.text(0.48, 1.03, f'{\"q-value: \" + str(q_value) if q_value >= 0.05 else \"(q-value < 0.05)\"}', horizontalalignment='center', verticalalignment='center', transform=plt.gca().transAxes, fontsize=16, color='black')\n",
        "    plt.grid(True, linewidth=0.5)\n",
        "    plt.legend(loc='upper left', fontsize=18)\n",
        "    #plt.suptitle('Validation Cohort', fontsize=18, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLBPLZ5eKeKX"
      },
      "outputs": [],
      "source": [
        "plot_prediction_graph2(y_tests, y_pred_tests, r2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpaNXaTktSR5"
      },
      "outputs": [],
      "source": [
        "#evaluate_based_on_feature_number(X_selected_scaled, y, RandomForestRegressor(random_state=0), kf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfGxjuNPtSR6"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def get_simple_feature_name(feature_names):\n",
        "    simple_names = []\n",
        "    for feature_name in feature_names:\n",
        "        simple_name = re.sub(r'\\(.*?\\)', '', feature_name)\n",
        "        simple_name = re.sub(r'\\[.*?\\]', '', simple_name)\n",
        "\n",
        "        simple_name = simple_name.strip()\n",
        "\n",
        "        if simple_name in simple_names:\n",
        "            last_underscore_index = feature_name.rfind('_')\n",
        "            simple_name = feature_name if last_underscore_index == -1 else feature_name[last_underscore_index:]\n",
        "        simple_names.append(simple_name)\n",
        "    return simple_names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ip9DRuO0tSR6"
      },
      "outputs": [],
      "source": [
        "feature_names = X.columns\n",
        "X_selected_scaled_df = pd.DataFrame(X_selected_scaled, columns=feature_names)\n",
        "X_selected_scaled_df\n",
        "\n",
        "X_selected_scaled_df.columns = get_simple_feature_name(X_selected_scaled_df.columns)\n",
        "X_selected_scaled_df.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rug5SCDvtSR6"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(X_selected_scaled_df)\n",
        "\n",
        "plt.figure()\n",
        "shap.summary_plot(shap_values, X_selected_scaled_df, show=False)\n",
        "\n",
        "plt.gca().tick_params(axis='y', labelsize=17)\n",
        "\n",
        "plt.gca().tick_params(axis='x', labelsize=17)\n",
        "\n",
        "cbar = plt.gcf().axes[-1]\n",
        "cbar.tick_params(labelsize=17)\n",
        "cbar.set_ylabel(\"Feature Value\", fontsize=17)\n",
        "\n",
        "ax = plt.gca()\n",
        "ax.set_xlabel(\"SHAP Value (Impact on Model Output)\", fontsize=17)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvNQiSwI4xuR"
      },
      "outputs": [],
      "source": [
        "\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "mean_abs_shap_values = np.abs(shap_values).mean(axis=0)\n",
        "most_important_feature_index = np.argmax(mean_abs_shap_values)\n",
        "most_important_feature_name = X_selected_scaled_df.columns[most_important_feature_index]\n",
        "\n",
        "shap_feature_values = shap_values[:, most_important_feature_index]\n",
        "feature_values = X_selected_scaled_df.iloc[:, most_important_feature_index]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "sc = plt.scatter(feature_values, shap_feature_values, c=feature_values, cmap=\"bwr\", edgecolors='k')\n",
        "\n",
        "cbar = plt.colorbar(sc)\n",
        "cbar.set_label(\"Feature Value\", fontsize=15)\n",
        "\n",
        "plt.xticks(fontsize=15)\n",
        "plt.yticks(fontsize=15)\n",
        "plt.xlabel(f\"{most_important_feature_name} Value\", fontsize=15)\n",
        "plt.ylabel(\"SHAP Value (Impact on Model Output)\", fontsize=15)\n",
        "#plt.title(f\"Relationship Between {most_important_feature_name} and SHAP Values\", fontsize=15)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0dXbciC9oni"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def get_simple_feature_name2(feature_names):\n",
        "    simple_names = []\n",
        "    for feature_name in feature_names:\n",
        "        simple_name = re.sub(r'^(INTENSITY-HISTOGRAM_)', 'IH-', feature_name)\n",
        "        simple_name = re.sub(r'^(INTENSITY-BASED_)', 'IB-', simple_name)\n",
        "        simple_name = re.sub(r'\\(.*?\\)', '', simple_name)\n",
        "        simple_name = re.sub(r'\\[.*?\\]', '', simple_name)\n",
        "\n",
        "        simple_name = simple_name.strip()\n",
        "        if simple_name in simple_names:\n",
        "            last_underscore_index = feature_name.rfind('_')\n",
        "            simple_name = feature_name if last_underscore_index == -1 else feature_name[last_underscore_index:]\n",
        "        simple_names.append(simple_name)\n",
        "    return simple_names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuERHMB59xGy"
      },
      "outputs": [],
      "source": [
        "feature_names = X.columns\n",
        "X_selected_scaled_df = pd.DataFrame(X_selected_scaled, columns=feature_names)\n",
        "X_selected_scaled_df\n",
        "\n",
        "X_selected_scaled_df.columns = get_simple_feature_name2(X_selected_scaled_df.columns)\n",
        "X_selected_scaled_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubidiyw9lztL"
      },
      "outputs": [],
      "source": [
        "pip install lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73zlEryjiQoc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import shap\n",
        "import lime.lime_tabular\n",
        "import matplotlib.pyplot as plt\n",
        "import textwrap\n",
        "from math import pi\n",
        "\n",
        "# model = XGBRegressor()\n",
        "# model.fit(X_train, y_train)\n",
        "\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(X_selected_scaled_df)\n",
        "\n",
        "shap_importances = np.abs(shap_values).mean(axis=0)\n",
        "\n",
        "lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    X_selected_scaled_df.values,\n",
        "    feature_names=X_selected_scaled_df.columns.tolist(),\n",
        "    verbose=True,\n",
        "    mode=\"regression\",\n",
        "    random_state=106\n",
        "\n",
        ")\n",
        "\n",
        "lime_exp = lime_explainer.explain_instance(X_selected_scaled_df.iloc[0].values, model.predict, num_features=8)\n",
        "\n",
        "lime_weights_dict = dict(lime_exp.as_map()[0])\n",
        "\n",
        "lime_importances = np.array([lime_weights_dict.get(i, 0) for i in range(len(X_selected_scaled_df.columns))])\n",
        "\n",
        "shap_importances /= shap_importances.max()\n",
        "lime_importances = np.abs(lime_importances) / np.abs(lime_importances).max()\n",
        "\n",
        "feature_names = X_selected_scaled_df.columns\n",
        "\n",
        "shap_importances = np.append(shap_importances, shap_importances[0])\n",
        "lime_importances = np.append(lime_importances, lime_importances[0])\n",
        "\n",
        "feature_names_wrapped = [\"\\n\".join(textwrap.wrap(name, width=15)) for name in feature_names]\n",
        "\n",
        "num_vars = len(feature_names)\n",
        "angles = np.linspace(0, 2 * pi, num_vars, endpoint=False).tolist()\n",
        "angles.append(angles[0])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 12), subplot_kw=dict(polar=True))\n",
        "\n",
        "ax.fill(angles, shap_importances, color='#C71585', alpha=0.25, label=\"SHAP\")\n",
        "ax.plot(angles, shap_importances, color='#663399', linewidth=2)\n",
        "\n",
        "ax.fill(angles, lime_importances, color='#87CEEB', alpha=0.25, label=\"LIME\")\n",
        "ax.plot(angles, lime_importances, color='#1E90FF', linewidth=2)\n",
        "\n",
        "ax.set_xticks(angles[:-1])\n",
        "for label, angle in zip(feature_names_wrapped, angles[:-1]):\n",
        "    rotation = np.degrees(angle)\n",
        "\n",
        "    if 240 < rotation < 280:\n",
        "        ha = \"center\"\n",
        "        rotation += 90\n",
        "    elif 70 < rotation < 110:\n",
        "        ha = \"center\"\n",
        "        rotation += 270\n",
        "    elif 110 < rotation < 270:\n",
        "        ha = \"right\"\n",
        "        rotation += 180\n",
        "    else:\n",
        "        ha = \"left\"\n",
        "\n",
        "    ax.text(angle, 1.2, label, rotation=rotation, size=17, ha=ha, va=\"center\")\n",
        "\n",
        "ax.set_rlabel_position(0)\n",
        "plt.yticks([0.2, 0.6, 1.0], [\"0.2\", \"0.6\", \"1.0\"], color=\"grey\", size=10)\n",
        "plt.ylim(0, 1.1)\n",
        "ax.grid(color='#003399', linestyle=':', linewidth=1)\n",
        "\n",
        "plt.legend(loc=\"upper right\", bbox_to_anchor=(1.3, 1.1), fontsize=17)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lUo8edU__0O"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import shap\n",
        "import lime.lime_tabular\n",
        "import matplotlib.pyplot as plt\n",
        "import textwrap\n",
        "from math import pi\n",
        "\n",
        "# model = XGBRegressor()\n",
        "# model.fit(X_train, y_train)\n",
        "\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(X_selected_scaled_df)\n",
        "\n",
        "shap_importances = np.abs(shap_values).mean(axis=0)\n",
        "\n",
        "lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    X_selected_scaled_df.values,\n",
        "    feature_names=X_selected_scaled_df.columns.tolist(),\n",
        "    verbose=True,\n",
        "    mode=\"regression\",\n",
        "    random_state=106\n",
        "\n",
        ")\n",
        "\n",
        "lime_exp = lime_explainer.explain_instance(X_selected_scaled_df.iloc[0].values, model.predict, num_features=10)\n",
        "\n",
        "lime_weights_dict = dict(lime_exp.as_map()[0])\n",
        "\n",
        "lime_importances = np.array([lime_weights_dict.get(i, 0) for i in range(len(X_selected_scaled_df.columns))])\n",
        "\n",
        "shap_importances /= shap_importances.max()\n",
        "lime_importances = np.abs(lime_importances) / np.abs(lime_importances).max()\n",
        "\n",
        "feature_names = X_selected_scaled_df.columns\n",
        "\n",
        "shap_importances = np.append(shap_importances, shap_importances[0])\n",
        "lime_importances = np.append(lime_importances, lime_importances[0])\n",
        "\n",
        "feature_names_wrapped = [\"\\n\".join(textwrap.wrap(name, width=9)) for name in feature_names]\n",
        "\n",
        "num_vars = len(feature_names)\n",
        "angles = np.linspace(0, 2 * pi, num_vars, endpoint=False).tolist()\n",
        "angles.append(angles[0])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 12), subplot_kw=dict(polar=True))\n",
        "\n",
        "ax.fill(angles, shap_importances, color='#C71585', alpha=0.25, label=\"SHAP\")\n",
        "ax.plot(angles, shap_importances, color='#663399', linewidth=2)\n",
        "\n",
        "ax.fill(angles, lime_importances, color='#87CEEB', alpha=0.25, label=\"LIME\")\n",
        "ax.plot(angles, lime_importances, color='#1E90FF', linewidth=2)\n",
        "\n",
        "ax.set_xticks(angles[:-1])\n",
        "for label, angle in zip(feature_names_wrapped, angles[:-1]):\n",
        "    rotation = np.degrees(angle)\n",
        "\n",
        "    if 240 < rotation < 280:\n",
        "        ha = \"center\"\n",
        "        rotation += 90\n",
        "    elif 90 < rotation < 110:\n",
        "        ha = \"center\"\n",
        "        rotation += 270\n",
        "    elif 110 < rotation < 270:\n",
        "        ha = \"right\"\n",
        "        rotation += 180\n",
        "    else:\n",
        "        ha = \"left\"\n",
        "\n",
        "    ax.text(angle, 1.2, label, rotation=rotation, size=17, ha=ha, va=\"center\")\n",
        "\n",
        "ax.set_rlabel_position(0)\n",
        "plt.yticks([0.2, 0.6, 1.0], [\"0.2\", \"0.6\", \"1.0\"], color=\"grey\", size=10)\n",
        "plt.ylim(0, 1.1)\n",
        "ax.grid(color='#003399', linestyle=':', linewidth=1)\n",
        "\n",
        "plt.legend(loc=\"upper right\", bbox_to_anchor=(1.3, 1.1), fontsize=17)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ixzw81bu-VSp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import shap\n",
        "import lime.lime_tabular\n",
        "import matplotlib.pyplot as plt\n",
        "import textwrap\n",
        "from math import pi\n",
        "\n",
        "# model = XGBRegressor()\n",
        "# model.fit(X_train, y_train)\n",
        "\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(X_selected_scaled_df)\n",
        "\n",
        "shap_importances = np.abs(shap_values).mean(axis=0)\n",
        "\n",
        "lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    X_selected_scaled_df.values,\n",
        "    feature_names=X_selected_scaled_df.columns.tolist(),\n",
        "    verbose=True,\n",
        "    mode=\"regression\",\n",
        "    random_state=106\n",
        "\n",
        ")\n",
        "\n",
        "lime_exp = lime_explainer.explain_instance(X_selected_scaled_df.iloc[0].values, model.predict, num_features=16)\n",
        "\n",
        "lime_weights_dict = dict(lime_exp.as_map()[0])\n",
        "\n",
        "lime_importances = np.array([lime_weights_dict.get(i, 0) for i in range(len(X_selected_scaled_df.columns))])\n",
        "\n",
        "shap_importances /= shap_importances.max()\n",
        "lime_importances = np.abs(lime_importances) / np.abs(lime_importances).max()\n",
        "\n",
        "feature_names = X_selected_scaled_df.columns\n",
        "\n",
        "shap_importances = np.append(shap_importances, shap_importances[0])\n",
        "lime_importances = np.append(lime_importances, lime_importances[0])\n",
        "\n",
        "feature_names_wrapped = [\"\\n\".join(textwrap.wrap(name, width=9)) for name in feature_names]\n",
        "\n",
        "num_vars = len(feature_names)\n",
        "angles = np.linspace(0, 2 * pi, num_vars, endpoint=False).tolist()\n",
        "angles.append(angles[0])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 12), subplot_kw=dict(polar=True))\n",
        "\n",
        "ax.fill(angles, shap_importances, color='#C71585', alpha=0.25, label=\"SHAP\")\n",
        "ax.plot(angles, shap_importances, color='#663399', linewidth=2)\n",
        "\n",
        "ax.fill(angles, lime_importances, color='#87CEEB', alpha=0.25, label=\"LIME\")\n",
        "ax.plot(angles, lime_importances, color='#1E90FF', linewidth=2)\n",
        "\n",
        "ax.set_xticks(angles[:-1])\n",
        "for label, angle in zip(feature_names_wrapped, angles[:-1]):\n",
        "    rotation = np.degrees(angle)\n",
        "\n",
        "    if 250 < rotation < 280:\n",
        "        ha = \"right\"\n",
        "        rotation += 90\n",
        "    elif 80 < rotation < 110:\n",
        "        ha = \"center\"\n",
        "        rotation += 270\n",
        "    elif 110 < rotation < 270:\n",
        "        ha = \"right\"\n",
        "        rotation += 180\n",
        "    else:\n",
        "        ha = \"left\"\n",
        "\n",
        "    ax.text(angle, 1.22, label, rotation=rotation, size=17, ha=ha, va=\"center\")\n",
        "\n",
        "ax.set_rlabel_position(0)\n",
        "plt.yticks([0.2, 0.6, 1.0], [\"0.2\", \"0.6\", \"1.0\"], color=\"grey\", size=10)\n",
        "plt.ylim(0, 1.1)\n",
        "ax.grid(color='#003399', linestyle=':', linewidth=1)\n",
        "\n",
        "plt.legend(loc=\"upper right\", bbox_to_anchor=(1.3, 1.1), fontsize=17)\n",
        "\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 4627925,
          "sourceId": 7884184,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4703025,
          "sourceId": 7989110,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4708256,
          "sourceId": 7996517,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4808471,
          "sourceId": 8134587,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30684,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}